#! /usr/bin/python
# -*- coding: utf8 -*-
import sys
import codecs
import re
import glob


reload(sys)
sys.setdefaultencoding('utf-8')

inputfile = open('./vocab_no.txt','r')
inputlistfile = open('./lite.wordlist.wFacebookNDabaigouFreq.txt','r')


check_list = []
check_list_word = []
for vocab in inputfile:
    check_list.append(vocab.strip())

for line_word in inputlistfile:
    str_word = str(line_word).split('\t')[0]
    check_list_word.append(str_word)


def isnumeric(s):
    return all(c in "0123456789" for c in s)

def get_emoji():
    emoji_str = 'ï»¿ğŸ‘µ|ğŸ‘´|ğŸ‘·|ğŸ‘¶|ğŸ‘±|ğŸ‘°|ğŸ‘³|ğŸ‘²|ğŸ‘½|ğŸ‘¼|ğŸ‘¿|âœŠ|ğŸ‘¹|ğŸ‘¸|ğŸ‘»|ğŸ‘º|ğŸ‘¥|ğŸ‘¤|ğŸ‘§|ğŸ‘¦|â•|â˜”|ãŠ—|ğŸ‘¢|ğŸ‘­|ğŸ‘¬|ğŸ‘¯|ğŸ‘®|ğŸ‘©|ğŸ‘¨|ğŸ‘«|ğŸ‘ª|ğŸ†–|ğŸ†—|ğŸ†”|ğŸ†•|ğŸ†’|ğŸ†“|ğŸ‘“|ğŸ†‘|ğŸ‘|ğŸ‘œ|ğŸ‘Ÿ|ğŸ‘|ğŸ†š|ğŸ‘˜|ğŸ†˜|ğŸ†™|ğŸ‘…|ã€°|ğŸ‘‡|ğŸ‘†|ğŸ‘€|ğŸ‘ƒ|ğŸ‘‚|3âƒ£|ğŸ‘Œ|ğŸ‘|ğŸ‘|ğŸ‘‰|ğŸ‘ˆ|ğŸ‘‹|ğŸŒƒ|ğŸµ|ğŸ´|ğŸ·|ğŸ¶|ğŸ±|ğŸ°|ğŸ³|ğŸ²|ğŸ½|ğŸ¼|ğŸ¾|ğŸ¹|ğŸ¸|ğŸ»|ğŸº|ğŸ¥|ğŸ¤|ğŸ§|ğŸ¦|ğŸ¡|ğŸ |ğŸ£|ğŸ¢|ğŸ­|ğŸ¬|ğŸ¯|ğŸ®|ğŸ©|ğŸ¨|ğŸ«|ğŸ”|ğŸ•|ğŸ”|ğŸ—|ğŸŒ|ğŸ‘|ğŸ|ğŸ“|ğŸ’|ğŸ|ğŸœ|ğŸŸ|ğŸ|ğŸ™|ğŸ˜|ğŸ›|ğŸš|ğŸ…|ğŸ„|ğŸ‡|ğŸ†|ğŸ|ğŸ€|ğŸƒ|ğŸ‚|ğŸ|ğŸŒ|ğŸ|ğŸ|ğŸ‰|ğŸˆ|ğŸ‹|ğŸ‘ |ğŸ“µ|ğŸ“´|ğŸ“·|ğŸ“¶|âœ…|ğŸ‘£|ğŸ“³|ğŸ“²|ğŸ“¼|ğŸ“¹|ğŸš·|ğŸ“»|ğŸ“º|ğŸ“¥|ğŸ“¤|ğŸ“§|ğŸµ|ğŸ“¡|ğŸ“ |ğŸ“£|â†–|ğŸ“­|ğŸš±|ğŸ“¯|ğŸ“®|ğŸ“©|ğŸ“¨|ğŸ‘¡|ğŸ“ª|ğŸ“•|ğŸ“”|ğŸ“—|ğŸ“–|ğŸ“‘|ğŸ“|ğŸ““|ğŸ“’|ğŸ“|ğŸ“œ|ğŸ“Ÿ|ğŸ±|ğŸ“™|ğŸ“˜|ğŸ“›|ğŸ“š|ğŸ“…|ğŸ“„|ğŸ“‡|ğŸ“†|ğŸ“|ğŸ“€|ğŸ“ƒ|ğŸ“‚|ğŸ“|ğŸ“Œ|ğŸ“|ğŸ“|ğŸ“‰|ğŸ“ˆ|ğŸ“‹|ğŸ“Š|ğŸ’µ|ğŸ‘•|ğŸ’·|ğŸ‘¾|ğŸ’±|â›„|ğŸ…°|ğŸ…±|ğŸ…¾|ğŸ…¿|ğŸ’¿|ğŸ’¾|ğŸ’¹|ğŸ‘—|â™|ğŸ’º|ğŸ’¥|ğŸ’¤|ğŸ’§|ğŸ‘–|â•|â›”|ğŸ’£|ğŸ’¢|ğŸ’­|ğŸ‘‘|ğŸ’¯|ğŸ¹|ğŸ’©|ğŸ’¨|ğŸ’«|ğŸ‘|ğŸ’•|ğŸš¥|ğŸ’—|ğŸ’–|ğŸ’‘|ğŸ’|ğŸ’“|ğŸ§|ğŸ’|ğŸ’œ|ğŸ’Ÿ|ğŸ‘’|ğŸ’™|â™“|ğŸ’›|ğŸ’š|ğŸ’…|ğŸ’„|ğŸ’‡|ğŸ’†|ğŸ’|ğŸ’€|ğŸ’ƒ|ğŸ’‚|ğŸ’|ğŸ’Œ|ğŸ’|ğŸ’|ğŸ’‰|ğŸ’ˆ|â™¿|â—¾|ğŸš£|ğŸ‘™|ğŸ¡|ğŸ•¥|ğŸ®|ğŸ•§|ğŸ•¦|ğŸ•¡|âœ”|ğŸ•£|ğŸš¬|ğŸ‘š|â¬œ|ğŸ••|ğŸ•”|ğŸ•—|ğŸ•–|ğŸ•‘|ğŸ•|ğŸ•“|ğŸ‘„|ğŸ•|ğŸš©|ğŸ•Ÿ|ğŸ•|ğŸ•™|ğŸ•˜|ğŸ•›|ğŸ«|ğŸš«|ğŸ—¼|ğŸª|ğŸ©|ğŸ—¿|ğŸ”µ|ğŸ–|ğŸ”·|ğŸ”¶|â›…|â„|ğŸ”³|ğŸ”²|ğŸ”½|ğŸ”¼|â™Š|ğŸ”¹|ğŸš—|ğŸ”»|ğŸ”º|ğŸ”¥|ğŸ†|ğŸ”§|ğŸ”¦|ğŸ”¡|â”|ğŸ”£|ğŸ”¢|ğŸ”­|ğŸ’|ğŸ”¯|ğŸ”®|ğŸ”©|ğŸ”¨|ğŸ”«|ğŸ”ª|ğŸ”•|ğŸ””|ğŸ”—|ğŸ”–|ğŸ”‘|â¤|ğŸ”“|ğŸ”’|ğŸ”|ğŸ”œ|ğŸ”Ÿ|ğŸ‘|ğŸ”™|ğŸ”˜|ğŸ”›|ğŸ”š|ğŸ”…|ğŸš|ğŸš°|ğŸ”†|â›µ|ğŸ”€|ğŸ”ƒ|ğŸšœ|ğŸ”|ğŸƒ|ğŸ”|ğŸ‘Š|ğŸ”‰|ğŸšŸ|ğŸ”‹|ğŸ”Š|ğŸš|â¬‡|ğŸ—½|ğŸš|9âƒ£|ğŸ—¾|âœ|ğŸš˜|ğŸš³|â˜•|ğŸš›|ğŸšš|ğŸ†|ğŸ‡|âšª|ğŸ„|ğŸ€„|ğŸš†|ğŸš|ğŸ‹|ğŸƒ|ğŸ€|ğŸ|ğŸš|ğŸ|ğŸŒ|ğŸš|â™¥|ğŸŠ|â›ª|â¬|ğŸ‹|â›º|ğŸ¶|ğŸ·|ğŸ´|ğŸµ|ğŸ²|ğŸ³|ğŸ°|â¬†|ğŸ¾|ğŸ¿|ğŸ¼|ğŸ½|ğŸº|ğŸ»|ğŸ¸|ğŸ¹|ğŸ¦|ğŸ§|âš“|ğŸ¥|ğŸ¢|ğŸ£|ğŸ |ğŸ¡|ğŸ®|ğŸ¯|ğŸ¬|ğŸ­|ğŸª|ğŸ«|ğŸ¨|ğŸ©|â„¢|ğŸ’|ğŸ“|ğŸ|ğŸ‘|ğŸ¼|ğŸ™…|ğŸ‡|ğŸ™‡|ğŸ™†|ğŸ‚|ğŸ™€|ğŸ€|ğŸ|ğŸ™|ğŸ™Œ|ğŸ™|ğŸ™|ğŸ™‰|ğŸ™ˆ|ğŸ™‹|ğŸ™Š|ğŸ˜µ|ğŸ˜´|ğŸ˜·|ğŸ˜¶|ğŸ˜±|ğŸ˜°|ğŸ˜³|ğŸ˜²|ğŸ˜½|ğŸ˜¼|ğŸ˜¿|ğŸ˜¾|ğŸ˜¹|ğŸ˜¸|ğŸ˜»|ğŸ˜º|ğŸ˜¥|ğŸ˜¤|ğŸ˜§|ğŸ¥|ğŸ˜¡|ğŸ˜ |ğŸ˜£|ğŸ˜¢|ğŸ˜­|ğŸ¯|ğŸ¬|ğŸ­|ğŸ˜©|ğŸ˜¨|ğŸ˜«|ğŸ˜ª|ğŸ˜•|ğŸ˜”|ğŸ˜—|ğŸ˜–|ğŸ˜‘|ğŸ˜|ğŸ˜“|ğŸ˜’|ğŸ˜|ğŸ˜œ|ğŸ˜Ÿ|ğŸ˜|ğŸ‡¯ğŸ‡µ|ğŸ˜˜|ğŸ˜›|ğŸ˜š|ğŸ˜…|ğŸ˜„|â›³|ğŸ˜†|ğŸ˜|ğŸƒ|ğŸ˜ƒ|ğŸ˜‚|ğŸ˜|ğŸ˜Œ|ğŸ˜|ğŸ˜|ğŸ˜‰|ğŸ˜ˆ|ğŸ˜‹|ğŸ˜Š|ğŸŒ·|ğŸŒ´|ğŸŒµ|ğŸº|ğŸŒ³|ğŸŒ°|ğŸŒ±|âœ‰|ğŸŒ¿|ğŸŒ¼|ğŸŒ½|ğŸŒº|ğŸŒ»|ğŸŒ¸|ğŸŒ¹|ğŸŒ |ğŸŒ–|ğŸŒ—|ğŸŒ”|ğŸŒ•|ğŸŒ’|ğŸŒ“|ğŸŒ|ğŸŒ‘|ğŸŒ|ğŸŒŸ|ğŸŒœ|â–ª|ğŸŒš|ğŸŒ›|ğŸŒ˜|ğŸŒ™|ğŸŒ†|ğŸŒ‡|ğŸŒ„|ğŸŒ…|ğŸŒ‚|ğŸ›€|ğŸŒ€|ğŸŒ|ğŸŒ|ğŸŒ|ğŸŒŒ|ğŸ”|ğŸŒŠ|ğŸŒ‹|ğŸŒˆ|ğŸŒ‰|ğŸ¶|ğŸ·|ğŸ´|ğŸš¶|ğŸ²|ğŸ³|ğŸ°|ğŸš²|ğŸš½|ğŸš¼|ğŸš¿|ğŸš¾|ğŸš¹|ğŸ»|ğŸš»|ğŸšº|ğŸ¦|ğŸš¤|ğŸš§|ğŸ¥|ğŸ¢|ğŸ£|ğŸ |ğŸš¢|ğŸš­|ğŸ¯|ğŸ¬|ğŸ­|ğŸª|ğŸš¨|ğŸ¨|ğŸšª|ğŸš•|ğŸ—|ğŸ”|ğŸ•|ğŸš‘|ğŸ“|ğŸš“|ğŸš’|ğŸ|ğŸŸ|ğŸœ|ğŸ|ğŸš™|ğŸ›|ğŸ˜|ğŸ™|ğŸš…|ğŸš„|ğŸš‡|ğŸ…|ğŸ‚|ğŸš€|ğŸšƒ|2âƒ£|ğŸ|ğŸšŒ|ğŸš|ğŸ|ğŸš‰|ğŸšˆ|ğŸˆ|ğŸ‰|7âƒ£|âœˆ|â˜|ğŸ‡«ğŸ‡·|â†—|ğŸ“±|ğŸ“°|âœ¨|ğŸš¡|ğŸ¤|â™|â­|ğŸš |ğŸ”‡|â«|ğŸ“¦|ğŸˆ¶|ğŸˆ·|ğŸˆ´|ğŸˆµ|ğŸˆ²|ğŸˆ³|ğŸ“¢|ğŸˆº|ğŸˆ¸|ğŸˆ¹|ğŸ“¬|ğŸˆ¯|âŒ›|ğŸ‡·ğŸ‡º|ğŸ‘›|ğŸˆš|1âƒ£|ğŸˆ‚|ğŸ“«|ğŸˆ|ã€½|âš¾|â™‰|â›|â“|ğŸ‰|ğŸ‰‘|ğŸš¯|â°|âœ‚|ğŸš®|ğŸ˜¦|âœ’|â†™|âŒš|ğŸ‡°ğŸ‡·|â†©|ğŸ±|ğŸšŠ|#âƒ£|â™Œ|ğŸ–|ğŸ¤|0âƒ£|ğŸš¦|ğŸ”|â¬…|ğŸ’´|ğŸ’¶|ğŸ’°|ğŸ’³|ğŸ”¬|ğŸ’²|ğŸ’½|â–¶|â„¹|ğŸš”|ğŸ˜¬|ğŸ’¸|ğŸšµ|â­•|ğŸ’»|ğŸ‘|âª|ğŸš|ğŸ’¦|ğŸ—»|ğŸš–|ğŸ’¡|ğŸ’ |âœŒ|â—|ğŸ’¬|â™£|ğŸ†|ğŸ’®|Â©|â–«|ğŸŠ|ğŸ„|ğŸ…|ğŸ’ª|âš½|ğŸƒ|ğŸ’”|âŒ|ğŸ|â™’|ğŸ|ğŸŒ|ğŸ|ğŸŠ|ğŸ’’|â€¼|ğŸˆ|â—»|ğŸ‰|â›½|ğŸ’|ğŸ’˜|ğŸ|â†˜|â˜|â¬›|ğŸ°|ğŸ‘”|Â®|â™ˆ|â—€|6âƒ£|â‡|â‰|â™|ğŸŒ²|â—|ğŸ’¼|â|ğŸ¦|ğŸ¸|ğŸ§|ğŸ¤|ğŸ‡©ğŸ‡ª|â›²|ğŸ’‹|ğŸ¢|ğŸ’Š|ğŸ£|â˜€|ğŸ |ğŸ¡|ğŸ®|â†•|âœ–|ğŸ˜¯|â¡|ğŸ˜®|ğŸ‰|ğŸª|âš«|âœ³|ğŸ«|ğŸ¨|ğŸ©|ğŸ”‚|ğŸ”„|â™|â™ |ğŸ•¤|â©|ğŸ‡®ğŸ‡¹|â™¨|â—½|ğŸ• |ğŸ˜™|ğŸ•¢|ğŸ‡ªğŸ‡¸|â–|ğŸ“|âš |ğŸŒ|ğŸ‡|â†ª|ğŸ„|â¤µ|ğŸ‚|5âƒ£|ğŸ˜€|ğŸ€|â™‹|ğŸ|ğŸš¸|ğŸŠ|ğŸ•’|ğŸˆ|ğŸ•œ|â™»|ğŸ›…|ãŠ™|ğŸ›„|ğŸ•š|âš¡|ğŸŒ¾|â¤´|ğŸ”|âœ´|ğŸš‚|â˜º|8âƒ£|â™¦|ğŸ”Œ|â³|ğŸ›|4âƒ£|ğŸ‡ºğŸ‡¸|ğŸ‡¬ğŸ‡§|â˜|ğŸ”´|âœ‹|ğŸ‡¨ğŸ‡³|â˜‘|â†”|ğŸ”±|ğŸ”°|ğŸ›ƒ|â°|ğŸ˜‡|ğŸ†|â“‚|ğŸ›‚|ğŸ”¸|â™‘|ğŸš´|ğŸ”¤|â—¼|ğŸ” |ï¿½|â™¡|â˜…|â– |ğŸ˜‚|ğŸ‘Œ|ğŸš—|ğŸ’€|ğŸ˜’|ğŸ™|ğŸ‘|â¤|ğŸ˜¢|ğŸ™|ğŸ˜‚|â™¡|ğŸ’“|ğŸ˜|ğŸ”“|ğŸ’“|ğŸ˜­|ï¿½|ğŸ˜’|â¤|ğŸ’¨|âœ¨|~ğŸ’•|ğŸ‘|ğŸ§|ğŸ”¥|ğŸ’ª|ğŸ‘Š|ğŸ‘|ğŸ˜Œ|ğŸ˜ˆ|'
    return emoji_str

# é™¤å»è¯å°¾çš„æ ‡ç‚¹
def RemoveTailPunctuation(line_word, i):
    if 0 == len(line_word[i]):
        return False
    word = unicode(line_word[i], 'utf-8')
    nLen = len(word)
    nDiff = 0
    sentence_end_flag = False
    sentence_end = [u'\'', u'\"', u':', u'ØŸ', u'ØŒ', u'Ø›']
    if word[-1] in sentence_end:
        sentence_end_flag = True
    symbol_list = [u"\'", u':', u'-', u'\"', u'&', u')', u'(', u'/', u'\\', u'[',
                   u']']
    numstr = u'0123456789'
    special_str = u'.ØŒÂ»Â«â€â€œâ€â€˜â€™@|ØŸâ€“^*%<>Ë‡'
    # special_str=special_str.decode('unicode_escape').encode("utf-8")
    for nIndex in range(nLen - 1, -1, -1):
        str = word[nIndex]
        if ((not str in symbol_list) and (not str in numstr) and (not str in special_str)):
            break
        else:
            nDiff = nDiff + 1
    line_word[i] = word[0:nLen - nDiff].encode('utf-8')

    return sentence_end_flag


# ç§»é™¤è¯å¼€å¤´çš„å¼•å·
def RemoveHeadQuotation(line_word, i):
    if (0 == len(line_word[i])):
        return False
    word = unicode(line_word[i], 'utf-8')
    nLen = len(word)
    nDiff = 0
    symbol_list = [u"\'", u':', u'-', u'\"', u'&', u')', u'(', u'/', u'\\', u'[',
                   u']']
    numstr = u'0123456789'
    special_str = u'.ØŒÂ»Â«â€â€œâ€â€˜â€™@|ØŸâ€“^*%<>Ë‡'
    for nIndex in range(0, nLen):
        str = word[nIndex]
        if ((not str in symbol_list) and (not str in numstr) and (not str in special_str)):
            break
        else:
            nDiff = nDiff + 1
    line_word[i] = word[nDiff:nLen].encode('utf-8')
    if 0 != nDiff:
        return True
    else:
        return False


def loadAllChars():
    #files = glob.glob("./character/*.txt") #æœ¬åœ°
    files = glob.glob("demo_for_format/character/*.txt") #é›†ç¾¤
    chars = set()
    for fpath in files:
        f = open(fpath)
        for line in f.readlines():
            line = line.decode("utf-8")
            if line.strip() == "":
                continue
            ch = line.strip().split("\t")[0]
            if ch == "-":
                continue
            chars.add(ch)
    return u"[" + u"".join(chars) + u"]+"
	
allchars = loadAllChars()
#allchars = u"[ĞĞ”Ğ˜ĞœĞ Ğ¤Ğ¨ÑŠĞ¬Ğ°Ğ´Ğ¸Ğ¼Ñ€ÃƒDÃ‡HÃ‹LÃPÃ“Å’TXÃ›Ã£dÃ§hÃ«lÃ¯pÃ³txÃ»Ã¿ÑÑƒĞ“Ğ—Ñ…Ğ›ĞŸĞ£Ñ‡'Ğ«/Ñ‰Ğ³Ğ·ÃˆĞ»Ñ‹Ğ¿ÑÃ€CGÑKOSÃ”WÃÃœÃ cgÃ¨kĞ¦osÃ´wÃ¼Ñ‘Ğ’Ğ–ĞšĞĞ¢&Ğª.Ğ²Ğ¶ĞºĞ¾ÃBFÃ‰JÃNÃ‘RÃ•VÃ™ZÃÃ¡bfÃ©jÃ­nÃ±rÃµvÃ¹Å¸zÃ½Ğ¯ĞĞ‘Ğ®Ñ‚Ğ•Ğ™ĞÑ„Ğ¡Ğ¥ÑĞ©Ñ†Ğ­Ğ±ĞµÑˆĞ¹Ğ½AÃ‚EÃ†IÃŠMÑŒQÅ“Ã’UYÃšaÃ¢eĞ§Ã¦iÃªmÃ®qÃ²uyÃº]+"
#allchars = u"[ĞĞ”Ğ˜ĞœĞ Ğ¤Ğ¨ÑŠĞ¬Ğ°Ğ´Ğ¸Ğ¼Ñ€ÃƒDÃ‡HÃ‹LÃPÃ“Å’TXÃ›\ÃŸÃ£dÃ§hÃ«lÃ¯pÃ³txÃ»Ã¿ÑÑƒĞ“Ğ—Ñ…Ğ›ĞŸĞ£Ñ‡'Ğ«/Ñ‰Ğ³Ğ·ÃˆĞ»Ñ‹Ğ¿ÑÃ€CÃ„GÑKÃŒOSÃ”WÃÃœÃ cÃ¤gÃ¨kĞ¦Ã¬osÃ´wÃ¼Ñ‘Ğ’Ğ–ĞšĞĞ¢&Ğª.Ğ²Ğ¶ĞºĞ¾ÃBFÃ‰JÃNÃ‘RÃ•VÃ™ZÃÃ¡bfÃ©jÃ­nÃ±rÃµvÃ¹Å¸zÃ½Ğ¯ĞĞ‘Ğ®Ñ‚Ğ•Ğ™ĞÑ„Ğ¡Ğ¥ÑĞ©Ñ†Ğ­Ğ±ĞµÑˆĞ¹áºĞ½AÃ‚EÃ†IÃŠMÑŒQÅ“Ã’UÃ–YÃšaÃ¢eĞ§Ã¦iÃªmÃ®qÃ²uÃ¶yÃº]+"
#print "allchars : " + allchars
sys.stderr.write("allchars : " + allchars + "\n")

# æŒ‰æ ‡ç‚¹åˆ†å¥
def get_sentence_clone(line,sentence_list):
    line = line.strip()
    line = re.sub('"|â€|â€œ|', '', line)
    line = re.sub('\.', ' .\n', line)
    line = re.sub('\?', ' ?\n', line)
    line = re.sub('\!', ' !\n', line)
    line_list_one = line.split('\n')
    allchar_pattern = allchars + "|\w+"
    for item in line_list_one:
        if re.search(allchar_pattern, unicode(item)):
            sentence_list.append(item.strip())

def get_sentence(line):
    line_list_one = line.split(';')
    sentence_1 = ""
    for i in range(len(line_list_one)):
        if len(line_list_one[i].strip()) == 0:
            continue
        else:
            if i + 1 == len(line_list_one):
                sentence_1 += line_list_one[i].strip()
            else:
                sentence_1 += line_list_one[i].strip() + ' ; '

    line_list = sentence_1.split(',')
    sentence = ""
    for i in range(len(line_list)):
        if len(line_list[i].strip()) == 0:
            continue
        else:
            if i + 1 == len(line_list):
                sentence += line_list[i].strip()
            else:
                sentence += line_list[i].strip() + ' , '
    
    word_list = sentence.split(' ')
    str_temp = ''
    for word in word_list:
        if len(word) == 0:
            continue
        if word[0]=='\'':
            word = word[1:]
        if word[len(word)-1] == '\'':
            word = word[0:-1]
        #if word in check_list:
        #   continue
        
        #if len(word)>1 and word not in check_list_word: #or word != 'NUM' or word != 'USER':
        #   continue    
        if len(word) == 1 and word == '-':
            continue
        str_temp += word+' '        
                    
    return str_temp

invalid_alone_tags = set(["'", '"'])
def modify_word(word):
    chs = set(word)	
    if len(chs) == 1 and chs <= invalid_alone_tags:
        return ""
    while word[0] in invalid_alone_tags:
        word = word[1:]
    while word[-1] in invalid_alone_tags:
        word = word[:-1]
    return word

# remove continuous same char
cont_chars = set(['-'])
def modify_sent(sent):
    new_sent = ""
    lastch = ""
    for ch in cont_chars:
        for i in range(len(sent)):
            if sent[i] == ch and ch == lastch:
                continue
            new_sent += sent[i]
            lastch = sent[i]
    return new_sent


for line in sys.stdin:
    try:
        oriline = line.strip()
        infos = oriline.split("\t")
	
        if len(infos) != 2:
            continue

        lang = infos[0].strip()
        sent = infos[1].strip()
        
        words = sent.split(' ')
        str_sentence = ''

        for word in words:
            word = word.strip()
            word = modify_word(word)
            if len(word)==0:
                continue
            elif word[0] == '#':
                continue
            else:
                str_sentence += word + ' '
        str_sentence = re.sub(',','#',str_sentence)

        # remove urls
        str_sentence = re.sub("(https?|ftp|file)://[-A-Za-z0-9+&@#/%?=~_|!:,.;]+[-A-Za-z0-9+&@#/%=~_|]", " ", str_sentence)
        
        # remove "<br>"
        str_sentence = re.sub("<br>", "", str_sentence)

        # filter characters
        pattern = allchars + "|\w+|\.|\?|@\w+|\!|#|;|\s+|\'|-|\d+"
        str_list = re.findall(pattern, unicode(str_sentence))


        # maintain @USER
        str_sentence = ''
        allchar_pattern = allchars + "|\w+|@\w+"
        for str_word in str_list:
            str_word = str_word.encode('utf-8')
            if len(str_sentence)==0 and (re.match(allchar_pattern, unicode(str_word))):
                str_sentence += str_word.strip()+' '
            elif len(str_sentence)>0 and str_word != '\'' and str_word != '-':
                str_sentence += str_word.strip()+' '
            elif str_word == '\'' or str_word == '-':
                str_sentence = str_sentence.strip()
                str_sentence += str_word.strip()
        word_list = str_sentence.split(' ')
        #for i in range(len(word_list)):
        #    RemoveTailPunctuation(word_list, i)
        #for i in range(len(word_list)):
        #    RemoveHeadQuotation(word_list, i)
        str_sentence = ""
        for word_line in word_list:
            if len(word_line) > 0 and word_line != ' ':
                str_sentence += word_line + ' '

        sentence = str_sentence
        if len(sentence)==0:
            continue
        sentence = re.sub('_','',sentence)
        sentence = re.sub(get_emoji(),'',sentence)
        sentence = re.sub('\s+', ' ', sentence)
        sentence = re.sub(r'[,]+', ',', sentence)
        sentence = re.sub(r'[#]+', ',', sentence)
        sentence = re.sub('\s+', ' ', sentence)
        sentence_list=[]
        get_sentence_clone(sentence,sentence_list)
        new_sent = " ".join(sentence_list)

        newtext = get_sentence(new_sent)
        newtext = modify_sent(newtext)
        print lang + "\t" + newtext
    except Exception, e:
        sys.stderr.write(str(e))

